{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/LSTM_HPLC/blob/main/HPLC_20220409202200.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VoDnJFuApPY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS8T-dxnwfjO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFjap2PTfYbv"
      },
      "outputs": [],
      "source": [
        "#emoji_url=\"https://github.com/sipocz/Twitter-Sentiment-Analysis-AI-Challenge/raw/5e7d7d29f58be438f33fa0c0bc2fd251dea0b453/emoji.py\"\n",
        "#!rm emoji.py\n",
        "#!wget $emoji_url\n",
        "#import emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDUZMjUkgIIe",
        "outputId": "b98ade5b-3482-437d-e0c4-df4a6acce06d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '*Nmer2*': No such file or directory\n",
            "--2022-04-09 14:09:11--  https://github.com/sipocz/LSTM_HPLC/raw/3a447ab5d1d37cdcbcb4d931ce7d73518359c8b2/orig/Nmer2.csv\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/sipocz/LSTM_HPLC/3a447ab5d1d37cdcbcb4d931ce7d73518359c8b2/orig/Nmer2.csv [following]\n",
            "--2022-04-09 14:09:11--  https://raw.githubusercontent.com/sipocz/LSTM_HPLC/3a447ab5d1d37cdcbcb4d931ce7d73518359c8b2/orig/Nmer2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15772588 (15M) [text/plain]\n",
            "Saving to: ‘Nmer2.csv’\n",
            "\n",
            "Nmer2.csv           100%[===================>]  15.04M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-04-09 14:09:12 (132 MB/s) - ‘Nmer2.csv’ saved [15772588/15772588]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm *Nmer2*\n",
        "\n",
        "!wget https://github.com/sipocz/LSTM_HPLC/raw/3a447ab5d1d37cdcbcb4d931ce7d73518359c8b2/orig/Nmer2.csv\n",
        "#!wget https://github.com/sipocz/LSTM_HPLC/raw/4371b1ef331c9d0f304e25117f160b979bb39661/orig/N_m3.csv\n",
        "\n",
        "_MODE_=\"Tesztel\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFiNZuPMkfGl"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"Nmer2.csv\",sep=\",\",skiprows=1,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCjVAcb2iJZy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "YDtEcJB5haQF",
        "outputId": "0b3d5c50-be16-4d41-f9d1-5556f465553d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 time        0  0.00333333  0.00666667      0.01  0.0133333  \\\n",
              "0  M13127N_detect3020  1.68793     1.41315    0.755643  0.480864   0.255152   \n",
              "1  M13144N_detect3020  1.92345     1.32483    0.863592  0.559372   0.323847   \n",
              "2  M13153N_detect3020  1.88420     1.27576    0.853778  0.569185   0.333661   \n",
              "3  M14028N_detect3020  0.00000     1.42296    0.942100  0.598626   0.382728   \n",
              "4  M14049N_detect3020  1.59961     1.07949    0.706575  0.441609   0.235525   \n",
              "\n",
              "   0.0166667      0.02  0.0233333  0.0266667  ...  47.9167  47.92  47.9233  \\\n",
              "0   0.107949  0.000000        0.0        0.0  ...      0.0    0.0      0.0   \n",
              "1   0.176644  0.039254        0.0        0.0  ...      0.0    0.0      0.0   \n",
              "2   0.166830  0.039254        0.0        0.0  ...      0.0    0.0      0.0   \n",
              "3   0.206084  0.058881        0.0        0.0  ...      0.0    0.0      0.0   \n",
              "4   0.117762  0.000000        0.0        0.0  ...      0.0    0.0      0.0   \n",
              "\n",
              "   47.9267  47.93  47.9333  47.9367  47.94  Unnamed: 14384  Unnamed: 14385  \n",
              "0      0.0    0.0      0.0      0.0    0.0     2524.709798        megfelel  \n",
              "1      0.0    0.0      0.0      0.0    0.0     2422.244040        megfelel  \n",
              "2      0.0    0.0      0.0      0.0    0.0     2529.530277        megfelel  \n",
              "3      0.0    0.0      0.0      0.0    0.0     2433.146990        megfelel  \n",
              "4      0.0    0.0      0.0      0.0    0.0     2652.605677        megfelel  \n",
              "\n",
              "[5 rows x 14386 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef6e79a3-c8f4-4f92-9fe8-d563b96d9a10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>0</th>\n",
              "      <th>0.00333333</th>\n",
              "      <th>0.00666667</th>\n",
              "      <th>0.01</th>\n",
              "      <th>0.0133333</th>\n",
              "      <th>0.0166667</th>\n",
              "      <th>0.02</th>\n",
              "      <th>0.0233333</th>\n",
              "      <th>0.0266667</th>\n",
              "      <th>...</th>\n",
              "      <th>47.9167</th>\n",
              "      <th>47.92</th>\n",
              "      <th>47.9233</th>\n",
              "      <th>47.9267</th>\n",
              "      <th>47.93</th>\n",
              "      <th>47.9333</th>\n",
              "      <th>47.9367</th>\n",
              "      <th>47.94</th>\n",
              "      <th>Unnamed: 14384</th>\n",
              "      <th>Unnamed: 14385</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M13127N_detect3020</td>\n",
              "      <td>1.68793</td>\n",
              "      <td>1.41315</td>\n",
              "      <td>0.755643</td>\n",
              "      <td>0.480864</td>\n",
              "      <td>0.255152</td>\n",
              "      <td>0.107949</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2524.709798</td>\n",
              "      <td>megfelel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M13144N_detect3020</td>\n",
              "      <td>1.92345</td>\n",
              "      <td>1.32483</td>\n",
              "      <td>0.863592</td>\n",
              "      <td>0.559372</td>\n",
              "      <td>0.323847</td>\n",
              "      <td>0.176644</td>\n",
              "      <td>0.039254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2422.244040</td>\n",
              "      <td>megfelel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M13153N_detect3020</td>\n",
              "      <td>1.88420</td>\n",
              "      <td>1.27576</td>\n",
              "      <td>0.853778</td>\n",
              "      <td>0.569185</td>\n",
              "      <td>0.333661</td>\n",
              "      <td>0.166830</td>\n",
              "      <td>0.039254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2529.530277</td>\n",
              "      <td>megfelel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M14028N_detect3020</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.42296</td>\n",
              "      <td>0.942100</td>\n",
              "      <td>0.598626</td>\n",
              "      <td>0.382728</td>\n",
              "      <td>0.206084</td>\n",
              "      <td>0.058881</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2433.146990</td>\n",
              "      <td>megfelel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M14049N_detect3020</td>\n",
              "      <td>1.59961</td>\n",
              "      <td>1.07949</td>\n",
              "      <td>0.706575</td>\n",
              "      <td>0.441609</td>\n",
              "      <td>0.235525</td>\n",
              "      <td>0.117762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2652.605677</td>\n",
              "      <td>megfelel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 14386 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef6e79a3-c8f4-4f92-9fe8-d563b96d9a10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef6e79a3-c8f4-4f92-9fe8-d563b96d9a10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef6e79a3-c8f4-4f92-9fe8-d563b96d9a10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[31]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGJM5jz-elNX",
        "outputId": "33fc6823-004c-4389-bbab-d779546790c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time              M5C011N_detect3020\n",
              "0                                0.0\n",
              "0.00333333                   1.21688\n",
              "0.00666667                  0.755643\n",
              "0.01                         0.47105\n",
              "                         ...        \n",
              "47.9333                          0.0\n",
              "47.9367                          0.0\n",
              "47.94                            0.0\n",
              "Unnamed: 14384            2190.83243\n",
              "Unnamed: 14385              megfelel\n",
              "Name: 31, Length: 14386, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4arFXoEAuVVh"
      },
      "outputs": [],
      "source": [
        "col=df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DxpDNE_3TgCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA8Mk878pUdU"
      },
      "outputs": [],
      "source": [
        "df_X=df[col[11000:-2]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "fkrSKZswuyF1",
        "outputId": "a487491c-3ab6-435e-f712-9ccf847e1836"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   36.6633  36.6667  36.67  36.6733  36.6767  36.68  36.6833  36.6867  36.69  \\\n",
              "0      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "1      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "2      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "3      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "4      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "\n",
              "   36.6933  ...  47.91  47.9133  47.9167  47.92  47.9233  47.9267  47.93  \\\n",
              "0      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "1      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "2      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "3      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "4      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "\n",
              "   47.9333  47.9367  47.94  \n",
              "0      0.0      0.0    0.0  \n",
              "1      0.0      0.0    0.0  \n",
              "2      0.0      0.0    0.0  \n",
              "3      0.0      0.0    0.0  \n",
              "4      0.0      0.0    0.0  \n",
              "\n",
              "[5 rows x 3384 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6d7ac52-f24e-4967-b16b-c692a24c2ffc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>36.6633</th>\n",
              "      <th>36.6667</th>\n",
              "      <th>36.67</th>\n",
              "      <th>36.6733</th>\n",
              "      <th>36.6767</th>\n",
              "      <th>36.68</th>\n",
              "      <th>36.6833</th>\n",
              "      <th>36.6867</th>\n",
              "      <th>36.69</th>\n",
              "      <th>36.6933</th>\n",
              "      <th>...</th>\n",
              "      <th>47.91</th>\n",
              "      <th>47.9133</th>\n",
              "      <th>47.9167</th>\n",
              "      <th>47.92</th>\n",
              "      <th>47.9233</th>\n",
              "      <th>47.9267</th>\n",
              "      <th>47.93</th>\n",
              "      <th>47.9333</th>\n",
              "      <th>47.9367</th>\n",
              "      <th>47.94</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3384 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6d7ac52-f24e-4967-b16b-c692a24c2ffc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6d7ac52-f24e-4967-b16b-c692a24c2ffc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6d7ac52-f24e-4967-b16b-c692a24c2ffc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_X.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x0YQyPvuTa_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OczaGqbTqKgz"
      },
      "outputs": [],
      "source": [
        "df_y=df[col[-2:-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLG_fYjUiUSU"
      },
      "outputs": [],
      "source": [
        "df_y2=df[col[-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCzr89LSiaM8",
        "outputId": "6c133cf4-dd88-4e4a-9368-2834793babda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      megfelel\n",
              "1      megfelel\n",
              "2      megfelel\n",
              "3      megfelel\n",
              "4      megfelel\n",
              "         ...   \n",
              "200    megfelel\n",
              "201    megfelel\n",
              "202    megfelel\n",
              "203    megfelel\n",
              "204    megfelel\n",
              "Name: Unnamed: 14385, Length: 205, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9oEj5UHjCg_"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "df[\"coded\"] = LE.fit_transform(df_y2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B5dWWjxB2yN"
      },
      "outputs": [],
      "source": [
        "df_y.columns=[\"Value\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_b6_UVJN64t",
        "outputId": "91c2df76-ddda-4632-c243-6aa47004dc8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     205.000000\n",
              "mean     2185.517049\n",
              "std       370.014482\n",
              "min       231.169975\n",
              "25%      2054.040078\n",
              "50%      2243.486861\n",
              "75%      2422.116922\n",
              "max      2739.643728\n",
              "Name: Value, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_y.Value.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDFiWnELjilf"
      },
      "outputs": [],
      "source": [
        "df_y2=df[\"coded\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo6w0xCWjij9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOBK9cMiBw2h"
      },
      "outputs": [],
      "source": [
        "def min_max_scaling(series):\n",
        "    return (series - series.min()) / (series.max() - series.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TflhyEeDCnWk",
        "outputId": "c955d919-8d8f-4277-e7fc-d4a8196ec18b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "231.1699753"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df_y.Value.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-MBR9tevMFW"
      },
      "outputs": [],
      "source": [
        "df_y_scaled=min_max_scaling(df_y.Value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vGSDdwGqneG",
        "outputId": "a08857c2-b626-46fc-e0b4-48b7a90fa173"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.914317\n",
              "1    0.873469\n",
              "2    0.916239\n",
              "3    0.877815\n",
              "4    0.965302\n",
              "Name: Value, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df_y_scaled.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwyEcsOxmiC1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzMOTKbN2G3R"
      },
      "source": [
        "##Mentés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8zcn0gafG-W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsQObqfegZ7M"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LshFLrqKMVuR"
      },
      "outputs": [],
      "source": [
        "#df_train=pd.read_csv(\"train_200.csv\")\n",
        "#df_test=pd.read_csv(\"test_200.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3HJcQ35MWAn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XomafEhUMWAp"
      },
      "source": [
        "### adatbetöltés mondatok betöltése"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w60OcdVMWAp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqbe8kFxgJav"
      },
      "source": [
        "##Tanulás"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRf3_wt9Bekb"
      },
      "outputs": [],
      "source": [
        "__MAXWORD__=len(df_X.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UwmBdEkijzv",
        "outputId": "1c50b229-1770-4c6b-b078-d1ae3e660cd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3384"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "__MAXWORD__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59MTn_Fs3SvW"
      },
      "outputs": [],
      "source": [
        "lstm_size=25   #25 90% körül teljesített \n",
        "max_input_length=__MAXWORD__\n",
        "\n",
        "\n",
        "n_out=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD2F2akc1TJ5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS2bWgXsz2zc",
        "outputId": "92b8831a-eb32-4e8f-bd9f-594c595e3afe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "\n",
        "#print(lens1)\n",
        "n_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "VKzA6vcSCEm-",
        "outputId": "bef2e32b-c1a1-4544-8f53-4a52b1038e08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Value\n",
              "count   205.000000\n",
              "mean   2185.517049\n",
              "std     370.014482\n",
              "min     231.169975\n",
              "25%    2054.040078\n",
              "50%    2243.486861\n",
              "75%    2422.116922\n",
              "max    2739.643728"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17044b57-e5ad-4721-a871-73126315055d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>205.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2185.517049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>370.014482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>231.169975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2054.040078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2243.486861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2422.116922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2739.643728</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17044b57-e5ad-4721-a871-73126315055d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17044b57-e5ad-4721-a871-73126315055d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17044b57-e5ad-4721-a871-73126315055d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df_y.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7UMww7mFieO"
      },
      "outputs": [],
      "source": [
        "bins_list=[i*20 for i in range(150)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8u2USy7wPTrB",
        "outputId": "321dfb03-f921-41cd-b764-512e5b19be17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Value\n",
              "0  2524.709798\n",
              "1  2422.244040\n",
              "2  2529.530277\n",
              "3  2433.146990\n",
              "4  2652.605677"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de5a5e72-055e-40c5-b9fa-16663e909623\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2524.709798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2422.244040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2529.530277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2433.146990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2652.605677</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de5a5e72-055e-40c5-b9fa-16663e909623')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de5a5e72-055e-40c5-b9fa-16663e909623 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de5a5e72-055e-40c5-b9fa-16663e909623');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df_y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXmx6l3eFicN"
      },
      "outputs": [],
      "source": [
        "to_big=df_y.Value[df_y.Value>3000].index.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGwptS6DR5d1",
        "outputId": "13d9203b-9027-4a46-de62-344eca733806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "to_big"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "cVrXRp4UE5Qk",
        "outputId": "8d759c2d-abea-43c9-b8c0-9269a88f12f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f558d3fba10>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df_y.hist(bins=bins_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMwhuw-yQRZy"
      },
      "outputs": [],
      "source": [
        "for i in to_big:\n",
        "    df_X=df_X.drop(index=i)\n",
        "    df_y=df_y.drop(index=i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XgbsvsWRhX9"
      },
      "outputs": [],
      "source": [
        "max_y=df_y.Value.max()\n",
        "min_y=df_y.Value.min()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iyuQlwKRw72",
        "outputId": "f91fe185-6ee0-4101-d4d1-41038eca30f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2739.643728, 231.1699753)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "(max_y,min_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3ujsNSQTYe4"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "df_y_minmax=min_max_scaler.fit_transform(pd.array(df_y.Value).reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2AHvh8HU0JU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q019xqnl-vmH"
      },
      "outputs": [],
      "source": [
        "df_X_minmax=df_X/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C01xxvPgJ1wP"
      },
      "outputs": [],
      "source": [
        "# start learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26U6UXRhmSUE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_name=\"HPLC\"\n",
        "def scheduler(epoch, lr):\n",
        "       #return 0.00003\n",
        "\n",
        "    '''    \n",
        "    maxx=0.00001\n",
        "    minn=0.001\n",
        "    frekvency=3\n",
        "    o=(epoch % frekvency)/frekvency * (maxx-minn)+minn\n",
        "    return o\n",
        "    '''\n",
        "        \n",
        "    if epoch<190:\n",
        "        return 0.0005  \n",
        "    elif epoch <80:\n",
        "        return 0.0001\n",
        "    elif epoch <85:\n",
        "        return 0.0005\n",
        "    elif epoch <190:\n",
        "        return 0.0001\n",
        "    \n",
        "    \n",
        "    return 0.00001\n",
        "    \n",
        "callback_LR = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "callbacks = [callback_LR,\n",
        "            \n",
        "            #savemodela,\n",
        "            ModelCheckpoint(filepath=model_name+\"_loss_{loss:.4f}_acc_{binary_accuracy:.4f}_val_acc_{val_binary_accuracy:.4f}.hdf5\", monitor='val_binary_accuracy',\n",
        "                            verbose=1, save_best_only=False, mode='max')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvvPuVNSxNa7"
      },
      "outputs": [],
      "source": [
        "# Importáld a megfelelő rétegeket\n",
        "from tensorflow.keras.layers import Input,Dense,Embedding,LSTM,TimeDistributed, Flatten, Bidirectional, Conv1D, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adadelta,Adam,SGD,Adamax,RMSprop\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy,categorical_crossentropy, mean_squared_error, mean_absolute_error, binary_crossentropy\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "K.clear_session\n",
        "x= Input(shape=(max_input_length,1,))\n",
        "\n",
        "#conv1=Conv1D(filters=8, kernel_size=2, padding='same', activation='relu')(embedded_x)\n",
        "#MP=MaxPooling1D(pool_size=1)(conv1)\n",
        "lstm_output= Bidirectional(LSTM(units=lstm_size,return_sequences=True,return_state=True,dropout=0.1))(x)  #,return_state=True\n",
        "lstm_output= Bidirectional(LSTM(units=lstm_size,return_sequences=True,dropout=0.1))(lstm_output)\n",
        "\n",
        "lstm_output=Dropout(0.1)(lstm_output)\n",
        "\n",
        "Dense_out=Flatten()(lstm_output)\n",
        "#Dense_out= Dense(50, activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(Dense_out)\n",
        "\n",
        "predictions= Dense(n_out, activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(Dense_out)\n",
        "model=Model(inputs=x, outputs=predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OPg96E_EHxew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rK1gsmAC8Wm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4e2OlSbPTxD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45ibq_LGCprS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSRx_qeySr-3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQpADS6gMHmd",
        "outputId": "47b0a3d2-685a-4a35-b808-90d019077a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 3384, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  [(None, 3384, 50),   5400        ['input_1[0][0]']                \n",
            "                                 (None, 25),                                                      \n",
            "                                 (None, 25),                                                      \n",
            "                                 (None, 25),                                                      \n",
            "                                 (None, 25)]                                                      \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 3384, 50)    15200       ['bidirectional[0][0]',          \n",
            " )                                                                'bidirectional[0][1]',          \n",
            "                                                                  'bidirectional[0][2]',          \n",
            "                                                                  'bidirectional[0][3]',          \n",
            "                                                                  'bidirectional[0][4]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 3384, 50)     0           ['bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 169200)       0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            169201      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 189,801\n",
            "Trainable params: 189,801\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzJYM8QeJyvI"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP22GO0AoZkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4756530d-e42e-49f6-fc92-a723932455f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'HPLC*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm  HPLC*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JssV4hq6oZih"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACrVf-TbJYDe"
      },
      "outputs": [],
      "source": [
        "#train_x = np.asarray(xtrain)\n",
        "#train_y = np.asarray(ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj_fAh_eKaSl",
        "outputId": "c3b325e3-24f4-44bc-b01e-2fbfaec1ebc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['36.6633', '36.6667', '36.67', '36.6733', '36.6767', '36.68', '36.6833',\n",
              "       '36.6867', '36.69', '36.6933',\n",
              "       ...\n",
              "       '47.91', '47.9133', '47.9167', '47.92', '47.9233', '47.9267', '47.93',\n",
              "       '47.9333', '47.9367', '47.94'],\n",
              "      dtype='object', length=3384)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "df_X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuXvaxZE-rq-",
        "outputId": "93efc910-ca7e-48cb-b6d7-45205691d922"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "200    0\n",
              "201    0\n",
              "202    0\n",
              "203    0\n",
              "204    0\n",
              "Name: coded, Length: 205, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df_y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcUtrkpY_Ny-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWIM4DP36S2L"
      },
      "outputs": [],
      "source": [
        "# Loss \n",
        "\n",
        "loss =binary_crossentropy  #mean_absolute_error #categorical_crossentropy \n",
        "# Optimizer\n",
        "optimizer = Adam(learning_rate=0.1) #Ízlés szerint...\n",
        " \n",
        "# Compilation\n",
        "#############\n",
        "\n",
        "model.compile(optimizer=optimizer,loss=loss,metrics=[\"binary_accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK7a0SH9oYM3"
      },
      "outputs": [],
      "source": [
        "def save_model():\n",
        "    _MODEL_TYPE_=\"lstm_hplc\"\n",
        "\n",
        "    model_name=_MODEL_TYPE_.upper()\n",
        "    callbacks = [callback_LR,\n",
        "            \n",
        "            #savemodela,\n",
        "            ModelCheckpoint(filepath=model_name+\"_LOSS_{loss:.5f}_VLOSS_{val_loss:.5f}_ACC_{accuracy:.4f}_VACC_{val_accuracy:.4f}_.hdf5\", monitor='val_binary_accuracy',\n",
        "                            verbose=1, save_best_only=True, mode='max')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ONvuYqbc-8qV",
        "outputId": "40958560-2f55-4271-a903-980746347a15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   36.6633  36.6667  36.67  36.6733  36.6767  36.68  36.6833  36.6867  36.69  \\\n",
              "0      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "1      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "2      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "3      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "4      0.0      0.0    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "\n",
              "   36.6933  ...  47.91  47.9133  47.9167  47.92  47.9233  47.9267  47.93  \\\n",
              "0      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "1      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "2      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "3      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "4      0.0  ...    0.0      0.0      0.0    0.0      0.0      0.0    0.0   \n",
              "\n",
              "   47.9333  47.9367  47.94  \n",
              "0      0.0      0.0    0.0  \n",
              "1      0.0      0.0    0.0  \n",
              "2      0.0      0.0    0.0  \n",
              "3      0.0      0.0    0.0  \n",
              "4      0.0      0.0    0.0  \n",
              "\n",
              "[5 rows x 3384 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04ef1ed7-9f1a-49ca-8e63-36b0530e0115\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>36.6633</th>\n",
              "      <th>36.6667</th>\n",
              "      <th>36.67</th>\n",
              "      <th>36.6733</th>\n",
              "      <th>36.6767</th>\n",
              "      <th>36.68</th>\n",
              "      <th>36.6833</th>\n",
              "      <th>36.6867</th>\n",
              "      <th>36.69</th>\n",
              "      <th>36.6933</th>\n",
              "      <th>...</th>\n",
              "      <th>47.91</th>\n",
              "      <th>47.9133</th>\n",
              "      <th>47.9167</th>\n",
              "      <th>47.92</th>\n",
              "      <th>47.9233</th>\n",
              "      <th>47.9267</th>\n",
              "      <th>47.93</th>\n",
              "      <th>47.9333</th>\n",
              "      <th>47.9367</th>\n",
              "      <th>47.94</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3384 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04ef1ed7-9f1a-49ca-8e63-36b0530e0115')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04ef1ed7-9f1a-49ca-8e63-36b0530e0115 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04ef1ed7-9f1a-49ca-8e63-36b0530e0115');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "df_X_minmax.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI1SqakKjNO6"
      },
      "outputs": [],
      "source": [
        "#model.load_weights(\"XXXX_0.06212.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_y2[188]=0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yQ8xl2wAVOV",
        "outputId": "52d65f10-1b90-4e05-9dea-091348cfac15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_y2[188]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuuuxuvLAozz",
        "outputId": "79e1fed6-ea94-4f20-d51c-d560ce2c53da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_MODE_=\"Tanul\""
      ],
      "metadata": {
        "id": "cN_KulIeAoyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lDs1Ey1HAZnw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "op-I834SFpUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2222ef-7073-48bc-885c-2cccfa74044d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5855 - binary_accuracy: 0.7554\n",
            "Epoch 1: saving model to HPLC_loss_0.5855_acc_0.7554_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 87s 5s/step - loss: 0.5855 - binary_accuracy: 0.7554 - val_loss: 0.5713 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 2/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5113 - binary_accuracy: 0.8098\n",
            "Epoch 2: saving model to HPLC_loss_0.5113_acc_0.8098_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.5113 - binary_accuracy: 0.8098 - val_loss: 0.6209 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 3/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4886 - binary_accuracy: 0.8098\n",
            "Epoch 3: saving model to HPLC_loss_0.4886_acc_0.8098_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4886 - binary_accuracy: 0.8098 - val_loss: 0.6146 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 4/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4727 - binary_accuracy: 0.8098\n",
            "Epoch 4: saving model to HPLC_loss_0.4727_acc_0.8098_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4727 - binary_accuracy: 0.8098 - val_loss: 0.7717 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 5/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4974 - binary_accuracy: 0.8043\n",
            "Epoch 5: saving model to HPLC_loss_0.4974_acc_0.8043_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.4974 - binary_accuracy: 0.8043 - val_loss: 0.6226 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 6/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4688 - binary_accuracy: 0.8043\n",
            "Epoch 6: saving model to HPLC_loss_0.4688_acc_0.8043_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4688 - binary_accuracy: 0.8043 - val_loss: 0.6156 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 7/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4567 - binary_accuracy: 0.8098\n",
            "Epoch 7: saving model to HPLC_loss_0.4567_acc_0.8098_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4567 - binary_accuracy: 0.8098 - val_loss: 0.6079 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 8/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4580 - binary_accuracy: 0.7935\n",
            "Epoch 8: saving model to HPLC_loss_0.4580_acc_0.7935_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.4580 - binary_accuracy: 0.7935 - val_loss: 0.5735 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 9/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4837 - binary_accuracy: 0.8043\n",
            "Epoch 9: saving model to HPLC_loss_0.4837_acc_0.8043_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4837 - binary_accuracy: 0.8043 - val_loss: 0.6257 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 10/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4473 - binary_accuracy: 0.8098\n",
            "Epoch 10: saving model to HPLC_loss_0.4473_acc_0.8098_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4473 - binary_accuracy: 0.8098 - val_loss: 0.6190 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 11/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4624 - binary_accuracy: 0.8152\n",
            "Epoch 11: saving model to HPLC_loss_0.4624_acc_0.8152_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4624 - binary_accuracy: 0.8152 - val_loss: 0.5726 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 12/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4746 - binary_accuracy: 0.8152\n",
            "Epoch 12: saving model to HPLC_loss_0.4746_acc_0.8152_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4746 - binary_accuracy: 0.8152 - val_loss: 0.5698 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 13/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4475 - binary_accuracy: 0.8152\n",
            "Epoch 13: saving model to HPLC_loss_0.4475_acc_0.8152_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4475 - binary_accuracy: 0.8152 - val_loss: 0.5923 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 14/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4343 - binary_accuracy: 0.8152\n",
            "Epoch 14: saving model to HPLC_loss_0.4343_acc_0.8152_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4343 - binary_accuracy: 0.8152 - val_loss: 0.6662 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 15/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4312 - binary_accuracy: 0.8261\n",
            "Epoch 15: saving model to HPLC_loss_0.4312_acc_0.8261_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.4312 - binary_accuracy: 0.8261 - val_loss: 0.6065 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 16/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4132 - binary_accuracy: 0.8098\n",
            "Epoch 16: saving model to HPLC_loss_0.4132_acc_0.8098_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4132 - binary_accuracy: 0.8098 - val_loss: 0.7361 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 17/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4187 - binary_accuracy: 0.8098\n",
            "Epoch 17: saving model to HPLC_loss_0.4187_acc_0.8098_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4187 - binary_accuracy: 0.8098 - val_loss: 0.6585 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 18/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4076 - binary_accuracy: 0.8098\n",
            "Epoch 18: saving model to HPLC_loss_0.4076_acc_0.8098_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.4076 - binary_accuracy: 0.8098 - val_loss: 0.7851 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 19/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4341 - binary_accuracy: 0.8152\n",
            "Epoch 19: saving model to HPLC_loss_0.4341_acc_0.8152_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4341 - binary_accuracy: 0.8152 - val_loss: 0.5873 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 20/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4037 - binary_accuracy: 0.8315\n",
            "Epoch 20: saving model to HPLC_loss_0.4037_acc_0.8315_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4037 - binary_accuracy: 0.8315 - val_loss: 0.6704 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 21/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3987 - binary_accuracy: 0.8043\n",
            "Epoch 21: saving model to HPLC_loss_0.3987_acc_0.8043_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3987 - binary_accuracy: 0.8043 - val_loss: 0.5802 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 22/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.5018 - binary_accuracy: 0.8152\n",
            "Epoch 22: saving model to HPLC_loss_0.5018_acc_0.8152_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.5018 - binary_accuracy: 0.8152 - val_loss: 0.6258 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 23/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3897 - binary_accuracy: 0.8370\n",
            "Epoch 23: saving model to HPLC_loss_0.3897_acc_0.8370_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3897 - binary_accuracy: 0.8370 - val_loss: 0.6936 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 24/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4183 - binary_accuracy: 0.8261\n",
            "Epoch 24: saving model to HPLC_loss_0.4183_acc_0.8261_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4183 - binary_accuracy: 0.8261 - val_loss: 0.6947 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 25/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4733 - binary_accuracy: 0.8207\n",
            "Epoch 25: saving model to HPLC_loss_0.4733_acc_0.8207_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4733 - binary_accuracy: 0.8207 - val_loss: 0.5341 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 26/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3994 - binary_accuracy: 0.8152\n",
            "Epoch 26: saving model to HPLC_loss_0.3994_acc_0.8152_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3994 - binary_accuracy: 0.8152 - val_loss: 0.6213 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 27/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3840 - binary_accuracy: 0.8207\n",
            "Epoch 27: saving model to HPLC_loss_0.3840_acc_0.8207_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3840 - binary_accuracy: 0.8207 - val_loss: 0.6285 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 28/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3620 - binary_accuracy: 0.8315\n",
            "Epoch 28: saving model to HPLC_loss_0.3620_acc_0.8315_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3620 - binary_accuracy: 0.8315 - val_loss: 0.5601 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 29/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3522 - binary_accuracy: 0.8533\n",
            "Epoch 29: saving model to HPLC_loss_0.3522_acc_0.8533_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3522 - binary_accuracy: 0.8533 - val_loss: 0.5848 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 30/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3616 - binary_accuracy: 0.8533\n",
            "Epoch 30: saving model to HPLC_loss_0.3616_acc_0.8533_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3616 - binary_accuracy: 0.8533 - val_loss: 0.5635 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 31/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3308 - binary_accuracy: 0.8533\n",
            "Epoch 31: saving model to HPLC_loss_0.3308_acc_0.8533_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3308 - binary_accuracy: 0.8533 - val_loss: 0.5476 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 32/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3202 - binary_accuracy: 0.8587\n",
            "Epoch 32: saving model to HPLC_loss_0.3202_acc_0.8587_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.3202 - binary_accuracy: 0.8587 - val_loss: 0.4379 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 33/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3873 - binary_accuracy: 0.8207\n",
            "Epoch 33: saving model to HPLC_loss_0.3873_acc_0.8207_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3873 - binary_accuracy: 0.8207 - val_loss: 0.7147 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 34/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3155 - binary_accuracy: 0.8750\n",
            "Epoch 34: saving model to HPLC_loss_0.3155_acc_0.8750_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 76s 5s/step - loss: 0.3155 - binary_accuracy: 0.8750 - val_loss: 0.5054 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 35/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3391 - binary_accuracy: 0.8696\n",
            "Epoch 35: saving model to HPLC_loss_0.3391_acc_0.8696_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3391 - binary_accuracy: 0.8696 - val_loss: 0.4780 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 36/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4060 - binary_accuracy: 0.8533\n",
            "Epoch 36: saving model to HPLC_loss_0.4060_acc_0.8533_val_acc_0.7143.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4060 - binary_accuracy: 0.8533 - val_loss: 0.5469 - val_binary_accuracy: 0.7143 - lr: 5.0000e-04\n",
            "Epoch 37/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3946 - binary_accuracy: 0.8370\n",
            "Epoch 37: saving model to HPLC_loss_0.3946_acc_0.8370_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3946 - binary_accuracy: 0.8370 - val_loss: 0.5326 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 38/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3518 - binary_accuracy: 0.8641\n",
            "Epoch 38: saving model to HPLC_loss_0.3518_acc_0.8641_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3518 - binary_accuracy: 0.8641 - val_loss: 0.5825 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 39/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3094 - binary_accuracy: 0.8804\n",
            "Epoch 39: saving model to HPLC_loss_0.3094_acc_0.8804_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3094 - binary_accuracy: 0.8804 - val_loss: 0.7720 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 40/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3426 - binary_accuracy: 0.8478\n",
            "Epoch 40: saving model to HPLC_loss_0.3426_acc_0.8478_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3426 - binary_accuracy: 0.8478 - val_loss: 0.7074 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 41/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3455 - binary_accuracy: 0.8587\n",
            "Epoch 41: saving model to HPLC_loss_0.3455_acc_0.8587_val_acc_0.7619.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3455 - binary_accuracy: 0.8587 - val_loss: 0.5415 - val_binary_accuracy: 0.7619 - lr: 5.0000e-04\n",
            "Epoch 42/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2806 - binary_accuracy: 0.8641\n",
            "Epoch 42: saving model to HPLC_loss_0.2806_acc_0.8641_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2806 - binary_accuracy: 0.8641 - val_loss: 0.4619 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 43/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2888 - binary_accuracy: 0.8750\n",
            "Epoch 43: saving model to HPLC_loss_0.2888_acc_0.8750_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2888 - binary_accuracy: 0.8750 - val_loss: 0.5113 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 44/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2971 - binary_accuracy: 0.8750\n",
            "Epoch 44: saving model to HPLC_loss_0.2971_acc_0.8750_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2971 - binary_accuracy: 0.8750 - val_loss: 0.3344 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 45/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3467 - binary_accuracy: 0.8370\n",
            "Epoch 45: saving model to HPLC_loss_0.3467_acc_0.8370_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3467 - binary_accuracy: 0.8370 - val_loss: 0.3988 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 46/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3195 - binary_accuracy: 0.8696\n",
            "Epoch 46: saving model to HPLC_loss_0.3195_acc_0.8696_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3195 - binary_accuracy: 0.8696 - val_loss: 0.3425 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 47/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3602 - binary_accuracy: 0.8478\n",
            "Epoch 47: saving model to HPLC_loss_0.3602_acc_0.8478_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3602 - binary_accuracy: 0.8478 - val_loss: 0.5442 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 48/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4041 - binary_accuracy: 0.8261\n",
            "Epoch 48: saving model to HPLC_loss_0.4041_acc_0.8261_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.4041 - binary_accuracy: 0.8261 - val_loss: 0.5316 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 49/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3710 - binary_accuracy: 0.8370\n",
            "Epoch 49: saving model to HPLC_loss_0.3710_acc_0.8370_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3710 - binary_accuracy: 0.8370 - val_loss: 0.5079 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 50/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3089 - binary_accuracy: 0.8804\n",
            "Epoch 50: saving model to HPLC_loss_0.3089_acc_0.8804_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3089 - binary_accuracy: 0.8804 - val_loss: 0.4672 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 51/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2737 - binary_accuracy: 0.8804\n",
            "Epoch 51: saving model to HPLC_loss_0.2737_acc_0.8804_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2737 - binary_accuracy: 0.8804 - val_loss: 0.4131 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 52/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2722 - binary_accuracy: 0.8967\n",
            "Epoch 52: saving model to HPLC_loss_0.2722_acc_0.8967_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2722 - binary_accuracy: 0.8967 - val_loss: 0.5530 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 53/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2661 - binary_accuracy: 0.8913\n",
            "Epoch 53: saving model to HPLC_loss_0.2661_acc_0.8913_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2661 - binary_accuracy: 0.8913 - val_loss: 0.6488 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 54/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3045 - binary_accuracy: 0.8804\n",
            "Epoch 54: saving model to HPLC_loss_0.3045_acc_0.8804_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3045 - binary_accuracy: 0.8804 - val_loss: 0.4946 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 55/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2806 - binary_accuracy: 0.8859\n",
            "Epoch 55: saving model to HPLC_loss_0.2806_acc_0.8859_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2806 - binary_accuracy: 0.8859 - val_loss: 0.4593 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 56/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2694 - binary_accuracy: 0.8967\n",
            "Epoch 56: saving model to HPLC_loss_0.2694_acc_0.8967_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2694 - binary_accuracy: 0.8967 - val_loss: 0.5829 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 57/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2580 - binary_accuracy: 0.9076\n",
            "Epoch 57: saving model to HPLC_loss_0.2580_acc_0.9076_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2580 - binary_accuracy: 0.9076 - val_loss: 0.5496 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 58/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3001 - binary_accuracy: 0.8641\n",
            "Epoch 58: saving model to HPLC_loss_0.3001_acc_0.8641_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3001 - binary_accuracy: 0.8641 - val_loss: 0.4526 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 59/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3212 - binary_accuracy: 0.8804\n",
            "Epoch 59: saving model to HPLC_loss_0.3212_acc_0.8804_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3212 - binary_accuracy: 0.8804 - val_loss: 0.3632 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 60/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2565 - binary_accuracy: 0.8913\n",
            "Epoch 60: saving model to HPLC_loss_0.2565_acc_0.8913_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2565 - binary_accuracy: 0.8913 - val_loss: 0.2695 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 61/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3288 - binary_accuracy: 0.8533\n",
            "Epoch 61: saving model to HPLC_loss_0.3288_acc_0.8533_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3288 - binary_accuracy: 0.8533 - val_loss: 0.4207 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 62/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3327 - binary_accuracy: 0.8587\n",
            "Epoch 62: saving model to HPLC_loss_0.3327_acc_0.8587_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3327 - binary_accuracy: 0.8587 - val_loss: 0.5527 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 63/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2616 - binary_accuracy: 0.8913\n",
            "Epoch 63: saving model to HPLC_loss_0.2616_acc_0.8913_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2616 - binary_accuracy: 0.8913 - val_loss: 0.3599 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 64/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2785 - binary_accuracy: 0.8859\n",
            "Epoch 64: saving model to HPLC_loss_0.2785_acc_0.8859_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2785 - binary_accuracy: 0.8859 - val_loss: 0.3919 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 65/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2495 - binary_accuracy: 0.8859\n",
            "Epoch 65: saving model to HPLC_loss_0.2495_acc_0.8859_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2495 - binary_accuracy: 0.8859 - val_loss: 0.3131 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 66/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2414 - binary_accuracy: 0.9076\n",
            "Epoch 66: saving model to HPLC_loss_0.2414_acc_0.9076_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2414 - binary_accuracy: 0.9076 - val_loss: 0.4576 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 67/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3089 - binary_accuracy: 0.8587\n",
            "Epoch 67: saving model to HPLC_loss_0.3089_acc_0.8587_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3089 - binary_accuracy: 0.8587 - val_loss: 0.4496 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 68/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3383 - binary_accuracy: 0.8478\n",
            "Epoch 68: saving model to HPLC_loss_0.3383_acc_0.8478_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3383 - binary_accuracy: 0.8478 - val_loss: 0.5423 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 69/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2350 - binary_accuracy: 0.9022\n",
            "Epoch 69: saving model to HPLC_loss_0.2350_acc_0.9022_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2350 - binary_accuracy: 0.9022 - val_loss: 0.3451 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 70/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2211 - binary_accuracy: 0.9185\n",
            "Epoch 70: saving model to HPLC_loss_0.2211_acc_0.9185_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2211 - binary_accuracy: 0.9185 - val_loss: 0.4372 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 71/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3706 - binary_accuracy: 0.8424\n",
            "Epoch 71: saving model to HPLC_loss_0.3706_acc_0.8424_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3706 - binary_accuracy: 0.8424 - val_loss: 0.5282 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 72/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2865 - binary_accuracy: 0.9130\n",
            "Epoch 72: saving model to HPLC_loss_0.2865_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2865 - binary_accuracy: 0.9130 - val_loss: 0.2874 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 73/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2434 - binary_accuracy: 0.8804\n",
            "Epoch 73: saving model to HPLC_loss_0.2434_acc_0.8804_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2434 - binary_accuracy: 0.8804 - val_loss: 0.3045 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 74/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2353 - binary_accuracy: 0.8967\n",
            "Epoch 74: saving model to HPLC_loss_0.2353_acc_0.8967_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2353 - binary_accuracy: 0.8967 - val_loss: 0.3202 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 75/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2590 - binary_accuracy: 0.8804\n",
            "Epoch 75: saving model to HPLC_loss_0.2590_acc_0.8804_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2590 - binary_accuracy: 0.8804 - val_loss: 0.4246 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 76/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2589 - binary_accuracy: 0.8750\n",
            "Epoch 76: saving model to HPLC_loss_0.2589_acc_0.8750_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2589 - binary_accuracy: 0.8750 - val_loss: 0.2843 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 77/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2174 - binary_accuracy: 0.9076\n",
            "Epoch 77: saving model to HPLC_loss_0.2174_acc_0.9076_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2174 - binary_accuracy: 0.9076 - val_loss: 0.1805 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 78/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2230 - binary_accuracy: 0.9130\n",
            "Epoch 78: saving model to HPLC_loss_0.2230_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2230 - binary_accuracy: 0.9130 - val_loss: 0.2370 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 79/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2102 - binary_accuracy: 0.9076\n",
            "Epoch 79: saving model to HPLC_loss_0.2102_acc_0.9076_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 79s 5s/step - loss: 0.2102 - binary_accuracy: 0.9076 - val_loss: 0.3472 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 80/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2451 - binary_accuracy: 0.9022\n",
            "Epoch 80: saving model to HPLC_loss_0.2451_acc_0.9022_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2451 - binary_accuracy: 0.9022 - val_loss: 0.3144 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 81/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2049 - binary_accuracy: 0.9076\n",
            "Epoch 81: saving model to HPLC_loss_0.2049_acc_0.9076_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2049 - binary_accuracy: 0.9076 - val_loss: 0.4927 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 82/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3151 - binary_accuracy: 0.8641\n",
            "Epoch 82: saving model to HPLC_loss_0.3151_acc_0.8641_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3151 - binary_accuracy: 0.8641 - val_loss: 0.3255 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 83/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3115 - binary_accuracy: 0.8533\n",
            "Epoch 83: saving model to HPLC_loss_0.3115_acc_0.8533_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3115 - binary_accuracy: 0.8533 - val_loss: 0.3973 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 84/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3310 - binary_accuracy: 0.8533\n",
            "Epoch 84: saving model to HPLC_loss_0.3310_acc_0.8533_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3310 - binary_accuracy: 0.8533 - val_loss: 0.3443 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 85/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2729 - binary_accuracy: 0.8641\n",
            "Epoch 85: saving model to HPLC_loss_0.2729_acc_0.8641_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2729 - binary_accuracy: 0.8641 - val_loss: 0.4763 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 86/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2699 - binary_accuracy: 0.8859\n",
            "Epoch 86: saving model to HPLC_loss_0.2699_acc_0.8859_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2699 - binary_accuracy: 0.8859 - val_loss: 0.5187 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 87/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2341 - binary_accuracy: 0.8859\n",
            "Epoch 87: saving model to HPLC_loss_0.2341_acc_0.8859_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2341 - binary_accuracy: 0.8859 - val_loss: 0.2590 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 88/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2222 - binary_accuracy: 0.8967\n",
            "Epoch 88: saving model to HPLC_loss_0.2222_acc_0.8967_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2222 - binary_accuracy: 0.8967 - val_loss: 0.1672 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 89/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2286 - binary_accuracy: 0.8967\n",
            "Epoch 89: saving model to HPLC_loss_0.2286_acc_0.8967_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2286 - binary_accuracy: 0.8967 - val_loss: 0.2366 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 90/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2542 - binary_accuracy: 0.9076\n",
            "Epoch 90: saving model to HPLC_loss_0.2542_acc_0.9076_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2542 - binary_accuracy: 0.9076 - val_loss: 0.2158 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 91/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2333 - binary_accuracy: 0.8750\n",
            "Epoch 91: saving model to HPLC_loss_0.2333_acc_0.8750_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2333 - binary_accuracy: 0.8750 - val_loss: 0.3128 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 92/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2518 - binary_accuracy: 0.9022\n",
            "Epoch 92: saving model to HPLC_loss_0.2518_acc_0.9022_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2518 - binary_accuracy: 0.9022 - val_loss: 0.8682 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 93/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3776 - binary_accuracy: 0.8533\n",
            "Epoch 93: saving model to HPLC_loss_0.3776_acc_0.8533_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3776 - binary_accuracy: 0.8533 - val_loss: 0.6084 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 94/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3633 - binary_accuracy: 0.8478\n",
            "Epoch 94: saving model to HPLC_loss_0.3633_acc_0.8478_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3633 - binary_accuracy: 0.8478 - val_loss: 0.7354 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 95/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2904 - binary_accuracy: 0.8750\n",
            "Epoch 95: saving model to HPLC_loss_0.2904_acc_0.8750_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2904 - binary_accuracy: 0.8750 - val_loss: 0.7133 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 96/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3471 - binary_accuracy: 0.8750\n",
            "Epoch 96: saving model to HPLC_loss_0.3471_acc_0.8750_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.3471 - binary_accuracy: 0.8750 - val_loss: 0.2931 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 97/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2191 - binary_accuracy: 0.9076\n",
            "Epoch 97: saving model to HPLC_loss_0.2191_acc_0.9076_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2191 - binary_accuracy: 0.9076 - val_loss: 0.2628 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 98/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2119 - binary_accuracy: 0.9293\n",
            "Epoch 98: saving model to HPLC_loss_0.2119_acc_0.9293_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2119 - binary_accuracy: 0.9293 - val_loss: 0.3947 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 99/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2251 - binary_accuracy: 0.9239\n",
            "Epoch 99: saving model to HPLC_loss_0.2251_acc_0.9239_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2251 - binary_accuracy: 0.9239 - val_loss: 0.4745 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 100/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2568 - binary_accuracy: 0.8696\n",
            "Epoch 100: saving model to HPLC_loss_0.2568_acc_0.8696_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2568 - binary_accuracy: 0.8696 - val_loss: 0.5246 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 101/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2638 - binary_accuracy: 0.8913\n",
            "Epoch 101: saving model to HPLC_loss_0.2638_acc_0.8913_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 86s 5s/step - loss: 0.2638 - binary_accuracy: 0.8913 - val_loss: 0.5204 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 102/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2548 - binary_accuracy: 0.8913\n",
            "Epoch 102: saving model to HPLC_loss_0.2548_acc_0.8913_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2548 - binary_accuracy: 0.8913 - val_loss: 0.2767 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 103/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2407 - binary_accuracy: 0.8913\n",
            "Epoch 103: saving model to HPLC_loss_0.2407_acc_0.8913_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2407 - binary_accuracy: 0.8913 - val_loss: 0.3062 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 104/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2505 - binary_accuracy: 0.8913\n",
            "Epoch 104: saving model to HPLC_loss_0.2505_acc_0.8913_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2505 - binary_accuracy: 0.8913 - val_loss: 0.1709 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 105/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2617 - binary_accuracy: 0.8804\n",
            "Epoch 105: saving model to HPLC_loss_0.2617_acc_0.8804_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2617 - binary_accuracy: 0.8804 - val_loss: 0.2469 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 106/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2177 - binary_accuracy: 0.9022\n",
            "Epoch 106: saving model to HPLC_loss_0.2177_acc_0.9022_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2177 - binary_accuracy: 0.9022 - val_loss: 0.3454 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 107/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2144 - binary_accuracy: 0.9130\n",
            "Epoch 107: saving model to HPLC_loss_0.2144_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2144 - binary_accuracy: 0.9130 - val_loss: 0.2795 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 108/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2176 - binary_accuracy: 0.9076\n",
            "Epoch 108: saving model to HPLC_loss_0.2176_acc_0.9076_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2176 - binary_accuracy: 0.9076 - val_loss: 0.3263 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 109/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2423 - binary_accuracy: 0.8913\n",
            "Epoch 109: saving model to HPLC_loss_0.2423_acc_0.8913_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2423 - binary_accuracy: 0.8913 - val_loss: 0.5024 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 110/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2563 - binary_accuracy: 0.8859\n",
            "Epoch 110: saving model to HPLC_loss_0.2563_acc_0.8859_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2563 - binary_accuracy: 0.8859 - val_loss: 0.3195 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 111/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2116 - binary_accuracy: 0.9293\n",
            "Epoch 111: saving model to HPLC_loss_0.2116_acc_0.9293_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2116 - binary_accuracy: 0.9293 - val_loss: 0.2546 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 112/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2090 - binary_accuracy: 0.9239\n",
            "Epoch 112: saving model to HPLC_loss_0.2090_acc_0.9239_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2090 - binary_accuracy: 0.9239 - val_loss: 0.1516 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 113/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2975 - binary_accuracy: 0.8641\n",
            "Epoch 113: saving model to HPLC_loss_0.2975_acc_0.8641_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2975 - binary_accuracy: 0.8641 - val_loss: 0.1704 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 114/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2343 - binary_accuracy: 0.8859\n",
            "Epoch 114: saving model to HPLC_loss_0.2343_acc_0.8859_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2343 - binary_accuracy: 0.8859 - val_loss: 0.1832 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 115/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2118 - binary_accuracy: 0.9076\n",
            "Epoch 115: saving model to HPLC_loss_0.2118_acc_0.9076_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2118 - binary_accuracy: 0.9076 - val_loss: 0.4382 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 116/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1964 - binary_accuracy: 0.9130\n",
            "Epoch 116: saving model to HPLC_loss_0.1964_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1964 - binary_accuracy: 0.9130 - val_loss: 0.1703 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 117/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2086 - binary_accuracy: 0.9130\n",
            "Epoch 117: saving model to HPLC_loss_0.2086_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2086 - binary_accuracy: 0.9130 - val_loss: 0.2435 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 118/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2041 - binary_accuracy: 0.9022\n",
            "Epoch 118: saving model to HPLC_loss_0.2041_acc_0.9022_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2041 - binary_accuracy: 0.9022 - val_loss: 0.3864 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 119/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2359 - binary_accuracy: 0.8641\n",
            "Epoch 119: saving model to HPLC_loss_0.2359_acc_0.8641_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2359 - binary_accuracy: 0.8641 - val_loss: 0.4219 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 120/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2274 - binary_accuracy: 0.9130\n",
            "Epoch 120: saving model to HPLC_loss_0.2274_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2274 - binary_accuracy: 0.9130 - val_loss: 0.2954 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 121/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2081 - binary_accuracy: 0.9130\n",
            "Epoch 121: saving model to HPLC_loss_0.2081_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2081 - binary_accuracy: 0.9130 - val_loss: 0.2167 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 122/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2334 - binary_accuracy: 0.8913\n",
            "Epoch 122: saving model to HPLC_loss_0.2334_acc_0.8913_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2334 - binary_accuracy: 0.8913 - val_loss: 0.2465 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 123/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2017 - binary_accuracy: 0.8967\n",
            "Epoch 123: saving model to HPLC_loss_0.2017_acc_0.8967_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2017 - binary_accuracy: 0.8967 - val_loss: 0.3789 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 124/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1999 - binary_accuracy: 0.9239\n",
            "Epoch 124: saving model to HPLC_loss_0.1999_acc_0.9239_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.1999 - binary_accuracy: 0.9239 - val_loss: 0.2006 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 125/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2721 - binary_accuracy: 0.8804\n",
            "Epoch 125: saving model to HPLC_loss_0.2721_acc_0.8804_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2721 - binary_accuracy: 0.8804 - val_loss: 0.2966 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 126/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2207 - binary_accuracy: 0.9076\n",
            "Epoch 126: saving model to HPLC_loss_0.2207_acc_0.9076_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2207 - binary_accuracy: 0.9076 - val_loss: 0.5125 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 127/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2231 - binary_accuracy: 0.9130\n",
            "Epoch 127: saving model to HPLC_loss_0.2231_acc_0.9130_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2231 - binary_accuracy: 0.9130 - val_loss: 0.4704 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 128/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2084 - binary_accuracy: 0.8804\n",
            "Epoch 128: saving model to HPLC_loss_0.2084_acc_0.8804_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2084 - binary_accuracy: 0.8804 - val_loss: 0.1546 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 129/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1862 - binary_accuracy: 0.9130\n",
            "Epoch 129: saving model to HPLC_loss_0.1862_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1862 - binary_accuracy: 0.9130 - val_loss: 0.2884 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 130/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2181 - binary_accuracy: 0.8804\n",
            "Epoch 130: saving model to HPLC_loss_0.2181_acc_0.8804_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2181 - binary_accuracy: 0.8804 - val_loss: 0.5452 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 131/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2571 - binary_accuracy: 0.8913\n",
            "Epoch 131: saving model to HPLC_loss_0.2571_acc_0.8913_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2571 - binary_accuracy: 0.8913 - val_loss: 0.4545 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 132/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2239 - binary_accuracy: 0.9239\n",
            "Epoch 132: saving model to HPLC_loss_0.2239_acc_0.9239_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2239 - binary_accuracy: 0.9239 - val_loss: 0.2089 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 133/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2126 - binary_accuracy: 0.9293\n",
            "Epoch 133: saving model to HPLC_loss_0.2126_acc_0.9293_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2126 - binary_accuracy: 0.9293 - val_loss: 0.2404 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 134/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1988 - binary_accuracy: 0.9185\n",
            "Epoch 134: saving model to HPLC_loss_0.1988_acc_0.9185_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.1988 - binary_accuracy: 0.9185 - val_loss: 0.1761 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 135/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1953 - binary_accuracy: 0.9239\n",
            "Epoch 135: saving model to HPLC_loss_0.1953_acc_0.9239_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1953 - binary_accuracy: 0.9239 - val_loss: 0.2108 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 136/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2746 - binary_accuracy: 0.8859\n",
            "Epoch 136: saving model to HPLC_loss_0.2746_acc_0.8859_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.2746 - binary_accuracy: 0.8859 - val_loss: 0.2205 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 137/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2725 - binary_accuracy: 0.8696\n",
            "Epoch 137: saving model to HPLC_loss_0.2725_acc_0.8696_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2725 - binary_accuracy: 0.8696 - val_loss: 0.4411 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 138/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2311 - binary_accuracy: 0.8967\n",
            "Epoch 138: saving model to HPLC_loss_0.2311_acc_0.8967_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2311 - binary_accuracy: 0.8967 - val_loss: 0.6249 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 139/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2754 - binary_accuracy: 0.8804\n",
            "Epoch 139: saving model to HPLC_loss_0.2754_acc_0.8804_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2754 - binary_accuracy: 0.8804 - val_loss: 0.2169 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 140/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2205 - binary_accuracy: 0.8859\n",
            "Epoch 140: saving model to HPLC_loss_0.2205_acc_0.8859_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2205 - binary_accuracy: 0.8859 - val_loss: 0.3511 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 141/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3145 - binary_accuracy: 0.8533\n",
            "Epoch 141: saving model to HPLC_loss_0.3145_acc_0.8533_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.3145 - binary_accuracy: 0.8533 - val_loss: 0.5478 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 142/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2372 - binary_accuracy: 0.8750\n",
            "Epoch 142: saving model to HPLC_loss_0.2372_acc_0.8750_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2372 - binary_accuracy: 0.8750 - val_loss: 0.4694 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 143/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2274 - binary_accuracy: 0.8913\n",
            "Epoch 143: saving model to HPLC_loss_0.2274_acc_0.8913_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2274 - binary_accuracy: 0.8913 - val_loss: 0.1723 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 144/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2203 - binary_accuracy: 0.9239\n",
            "Epoch 144: saving model to HPLC_loss_0.2203_acc_0.9239_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2203 - binary_accuracy: 0.9239 - val_loss: 0.2373 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 145/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1922 - binary_accuracy: 0.9239\n",
            "Epoch 145: saving model to HPLC_loss_0.1922_acc_0.9239_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.1922 - binary_accuracy: 0.9239 - val_loss: 0.4065 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 146/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2003 - binary_accuracy: 0.9239\n",
            "Epoch 146: saving model to HPLC_loss_0.2003_acc_0.9239_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2003 - binary_accuracy: 0.9239 - val_loss: 0.2539 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 147/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1846 - binary_accuracy: 0.9293\n",
            "Epoch 147: saving model to HPLC_loss_0.1846_acc_0.9293_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1846 - binary_accuracy: 0.9293 - val_loss: 0.1510 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 148/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2064 - binary_accuracy: 0.9076\n",
            "Epoch 148: saving model to HPLC_loss_0.2064_acc_0.9076_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2064 - binary_accuracy: 0.9076 - val_loss: 0.1653 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 149/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2347 - binary_accuracy: 0.9076\n",
            "Epoch 149: saving model to HPLC_loss_0.2347_acc_0.9076_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2347 - binary_accuracy: 0.9076 - val_loss: 0.1295 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 150/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2430 - binary_accuracy: 0.9022\n",
            "Epoch 150: saving model to HPLC_loss_0.2430_acc_0.9022_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2430 - binary_accuracy: 0.9022 - val_loss: 0.2213 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 151/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2015 - binary_accuracy: 0.9022\n",
            "Epoch 151: saving model to HPLC_loss_0.2015_acc_0.9022_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2015 - binary_accuracy: 0.9022 - val_loss: 0.3029 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 152/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1855 - binary_accuracy: 0.9185\n",
            "Epoch 152: saving model to HPLC_loss_0.1855_acc_0.9185_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1855 - binary_accuracy: 0.9185 - val_loss: 0.1711 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 153/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1912 - binary_accuracy: 0.9022\n",
            "Epoch 153: saving model to HPLC_loss_0.1912_acc_0.9022_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.1912 - binary_accuracy: 0.9022 - val_loss: 0.3804 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 154/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2250 - binary_accuracy: 0.9022\n",
            "Epoch 154: saving model to HPLC_loss_0.2250_acc_0.9022_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2250 - binary_accuracy: 0.9022 - val_loss: 0.1373 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 155/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1766 - binary_accuracy: 0.9402\n",
            "Epoch 155: saving model to HPLC_loss_0.1766_acc_0.9402_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1766 - binary_accuracy: 0.9402 - val_loss: 0.2090 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 156/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1798 - binary_accuracy: 0.9185\n",
            "Epoch 156: saving model to HPLC_loss_0.1798_acc_0.9185_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 80s 5s/step - loss: 0.1798 - binary_accuracy: 0.9185 - val_loss: 0.2463 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 157/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2241 - binary_accuracy: 0.8967\n",
            "Epoch 157: saving model to HPLC_loss_0.2241_acc_0.8967_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2241 - binary_accuracy: 0.8967 - val_loss: 0.2581 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 158/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1879 - binary_accuracy: 0.9130\n",
            "Epoch 158: saving model to HPLC_loss_0.1879_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1879 - binary_accuracy: 0.9130 - val_loss: 0.3410 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 159/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2139 - binary_accuracy: 0.9022\n",
            "Epoch 159: saving model to HPLC_loss_0.2139_acc_0.9022_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2139 - binary_accuracy: 0.9022 - val_loss: 0.1903 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 160/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1777 - binary_accuracy: 0.9185\n",
            "Epoch 160: saving model to HPLC_loss_0.1777_acc_0.9185_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1777 - binary_accuracy: 0.9185 - val_loss: 0.1757 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 161/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1767 - binary_accuracy: 0.9185\n",
            "Epoch 161: saving model to HPLC_loss_0.1767_acc_0.9185_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1767 - binary_accuracy: 0.9185 - val_loss: 0.2107 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 162/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2029 - binary_accuracy: 0.9185\n",
            "Epoch 162: saving model to HPLC_loss_0.2029_acc_0.9185_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2029 - binary_accuracy: 0.9185 - val_loss: 0.2197 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 163/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1814 - binary_accuracy: 0.9185\n",
            "Epoch 163: saving model to HPLC_loss_0.1814_acc_0.9185_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1814 - binary_accuracy: 0.9185 - val_loss: 0.2450 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 164/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1665 - binary_accuracy: 0.9457\n",
            "Epoch 164: saving model to HPLC_loss_0.1665_acc_0.9457_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1665 - binary_accuracy: 0.9457 - val_loss: 0.5440 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 165/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2444 - binary_accuracy: 0.9076\n",
            "Epoch 165: saving model to HPLC_loss_0.2444_acc_0.9076_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2444 - binary_accuracy: 0.9076 - val_loss: 0.9005 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 166/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2443 - binary_accuracy: 0.9130\n",
            "Epoch 166: saving model to HPLC_loss_0.2443_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2443 - binary_accuracy: 0.9130 - val_loss: 0.2916 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 167/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2079 - binary_accuracy: 0.9076\n",
            "Epoch 167: saving model to HPLC_loss_0.2079_acc_0.9076_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2079 - binary_accuracy: 0.9076 - val_loss: 0.3167 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 168/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1703 - binary_accuracy: 0.9348\n",
            "Epoch 168: saving model to HPLC_loss_0.1703_acc_0.9348_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1703 - binary_accuracy: 0.9348 - val_loss: 0.2807 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 169/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2141 - binary_accuracy: 0.9130\n",
            "Epoch 169: saving model to HPLC_loss_0.2141_acc_0.9130_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2141 - binary_accuracy: 0.9130 - val_loss: 0.1485 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 170/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2091 - binary_accuracy: 0.9076\n",
            "Epoch 170: saving model to HPLC_loss_0.2091_acc_0.9076_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2091 - binary_accuracy: 0.9076 - val_loss: 0.1751 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 171/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1841 - binary_accuracy: 0.9402\n",
            "Epoch 171: saving model to HPLC_loss_0.1841_acc_0.9402_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1841 - binary_accuracy: 0.9402 - val_loss: 0.2795 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 172/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2462 - binary_accuracy: 0.8804\n",
            "Epoch 172: saving model to HPLC_loss_0.2462_acc_0.8804_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2462 - binary_accuracy: 0.8804 - val_loss: 0.4499 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 173/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2248 - binary_accuracy: 0.9130\n",
            "Epoch 173: saving model to HPLC_loss_0.2248_acc_0.9130_val_acc_0.8571.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2248 - binary_accuracy: 0.9130 - val_loss: 0.3372 - val_binary_accuracy: 0.8571 - lr: 5.0000e-04\n",
            "Epoch 174/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2201 - binary_accuracy: 0.9076\n",
            "Epoch 174: saving model to HPLC_loss_0.2201_acc_0.9076_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2201 - binary_accuracy: 0.9076 - val_loss: 0.2643 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 175/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1954 - binary_accuracy: 0.8967\n",
            "Epoch 175: saving model to HPLC_loss_0.1954_acc_0.8967_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1954 - binary_accuracy: 0.8967 - val_loss: 0.2663 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 176/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1671 - binary_accuracy: 0.9293\n",
            "Epoch 176: saving model to HPLC_loss_0.1671_acc_0.9293_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1671 - binary_accuracy: 0.9293 - val_loss: 0.2629 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 177/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1650 - binary_accuracy: 0.9402\n",
            "Epoch 177: saving model to HPLC_loss_0.1650_acc_0.9402_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1650 - binary_accuracy: 0.9402 - val_loss: 0.2359 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 178/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1686 - binary_accuracy: 0.9293\n",
            "Epoch 178: saving model to HPLC_loss_0.1686_acc_0.9293_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1686 - binary_accuracy: 0.9293 - val_loss: 0.1877 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 179/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1687 - binary_accuracy: 0.9130\n",
            "Epoch 179: saving model to HPLC_loss_0.1687_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1687 - binary_accuracy: 0.9130 - val_loss: 0.2151 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 180/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2222 - binary_accuracy: 0.9076\n",
            "Epoch 180: saving model to HPLC_loss_0.2222_acc_0.9076_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2222 - binary_accuracy: 0.9076 - val_loss: 0.2778 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 181/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1831 - binary_accuracy: 0.9239\n",
            "Epoch 181: saving model to HPLC_loss_0.1831_acc_0.9239_val_acc_0.8095.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1831 - binary_accuracy: 0.9239 - val_loss: 0.7515 - val_binary_accuracy: 0.8095 - lr: 5.0000e-04\n",
            "Epoch 182/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2328 - binary_accuracy: 0.9130\n",
            "Epoch 182: saving model to HPLC_loss_0.2328_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2328 - binary_accuracy: 0.9130 - val_loss: 0.3107 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 183/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2012 - binary_accuracy: 0.9076\n",
            "Epoch 183: saving model to HPLC_loss_0.2012_acc_0.9076_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.2012 - binary_accuracy: 0.9076 - val_loss: 0.3464 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 184/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1998 - binary_accuracy: 0.9185\n",
            "Epoch 184: saving model to HPLC_loss_0.1998_acc_0.9185_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1998 - binary_accuracy: 0.9185 - val_loss: 0.2711 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 185/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1820 - binary_accuracy: 0.9185\n",
            "Epoch 185: saving model to HPLC_loss_0.1820_acc_0.9185_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1820 - binary_accuracy: 0.9185 - val_loss: 0.3004 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 186/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1948 - binary_accuracy: 0.9022\n",
            "Epoch 186: saving model to HPLC_loss_0.1948_acc_0.9022_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1948 - binary_accuracy: 0.9022 - val_loss: 0.1779 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 187/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1984 - binary_accuracy: 0.9130\n",
            "Epoch 187: saving model to HPLC_loss_0.1984_acc_0.9130_val_acc_0.9048.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1984 - binary_accuracy: 0.9130 - val_loss: 0.2003 - val_binary_accuracy: 0.9048 - lr: 5.0000e-04\n",
            "Epoch 188/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1896 - binary_accuracy: 0.9185\n",
            "Epoch 188: saving model to HPLC_loss_0.1896_acc_0.9185_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1896 - binary_accuracy: 0.9185 - val_loss: 0.1859 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 189/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2304 - binary_accuracy: 0.9022\n",
            "Epoch 189: saving model to HPLC_loss_0.2304_acc_0.9022_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 78s 5s/step - loss: 0.2304 - binary_accuracy: 0.9022 - val_loss: 0.1579 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n",
            "Epoch 190/190\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.1579 - binary_accuracy: 0.9185\n",
            "Epoch 190: saving model to HPLC_loss_0.1579_acc_0.9185_val_acc_0.9524.hdf5\n",
            "16/16 [==============================] - 77s 5s/step - loss: 0.1579 - binary_accuracy: 0.9185 - val_loss: 0.1683 - val_binary_accuracy: 0.9524 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Illesszük az adatra a modellt\n",
        "if _MODE_==\"Tanul\":\n",
        "    history=model.fit(\n",
        "            x=df_X_minmax,\n",
        "            y=df_y2, \n",
        "            epochs=190, \n",
        "            batch_size=12,\n",
        "            validation_split=0.1,         \n",
        "            callbacks=[callbacks]          \n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-history-plot"
      ],
      "metadata": {
        "id": "Y3yWoor3Hyt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbb4706-076f-4c2c-d523-1b697b026903"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-history-plot\n",
            "  Downloading tensorflow_history_plot-0.1.2.tar.gz (3.6 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tensorflow-history-plot) (2.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tensorflow-history-plot) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-history-plot) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-history-plot) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-history-plot) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-history-plot) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-history-plot) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->tensorflow-history-plot) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->tensorflow-history-plot) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (1.14.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (13.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (1.44.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (0.24.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-history-plot) (1.1.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->tensorflow-history-plot) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->tensorflow-history-plot) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->tensorflow-history-plot) (3.2.0)\n",
            "Building wheels for collected packages: tensorflow-history-plot\n",
            "  Building wheel for tensorflow-history-plot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-history-plot: filename=tensorflow_history_plot-0.1.2-py3-none-any.whl size=2539 sha256=0ad6f2f52d7a31de0cf1739b68e91eae37746868c1423b7c05b30092d605823c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/8a/41/dc3fe77b5ff9c82043337a82ff5e7097c4bae7935b71b129db\n",
            "Successfully built tensorflow-history-plot\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-history-plot\n",
            "Successfully installed tensorflow-history-plot-0.1.2 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "D4eRDUJximCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_history_plot import show_acc\n",
        "show_acc.plot(history)"
      ],
      "metadata": {
        "id": "ObGrOy0LHu3x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "c538b01d-53ff-485f-ca5b-93d3bec0e9d6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-b154ece21e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_history_plot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshow_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_history_plot/show_acc.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QeMALF9AHu2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_MODE_=\"Tesztel\""
      ],
      "metadata": {
        "id": "82AeWLEG1vsQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname=\"https://github.com/sipocz/LSTM_HPLC/raw/06624756748f10624ac1fff709b8547df65ece7a/models/XXXX_loss_0.1450_acc_0.9457_val_acc_0.9524_20220406215100.hdf5\"\n",
        "if _MODE_==\"Tesztel\":\n",
        "    #!rm XXXX*\n",
        "    !wget $fname"
      ],
      "metadata": {
        "id": "I132le63oAkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec312e4-7d5e-4235-ce28-8e1dc2708d1a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-09 18:14:49--  https://github.com/sipocz/LSTM_HPLC/raw/06624756748f10624ac1fff709b8547df65ece7a/models/XXXX_loss_0.1450_acc_0.9457_val_acc_0.9524_20220406215100.hdf5\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/sipocz/LSTM_HPLC/06624756748f10624ac1fff709b8547df65ece7a/models/XXXX_loss_0.1450_acc_0.9457_val_acc_0.9524_20220406215100.hdf5 [following]\n",
            "--2022-04-09 18:14:49--  https://raw.githubusercontent.com/sipocz/LSTM_HPLC/06624756748f10624ac1fff709b8547df65ece7a/models/XXXX_loss_0.1450_acc_0.9457_val_acc_0.9524_20220406215100.hdf5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2348640 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘XXXX_loss_0.1450_acc_0.9457_val_acc_0.9524_20220406215100.hdf5’\n",
            "\n",
            "XXXX_loss_0.1450_ac 100%[===================>]   2.24M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-04-09 18:14:50 (35.7 MB/s) - ‘XXXX_loss_0.1450_acc_0.9457_val_acc_0.9524_20220406215100.hdf5’ saved [2348640/2348640]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "el4jLBvoybTN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "05jpd7BjeYez"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname=\"XXXX_loss_0.1450_acc_0.9457_val_acc_0.9524_20220406215100.hdf5\""
      ],
      "metadata": {
        "id": "IrAfG02Lj1wr"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f0mdKjZBjb7L"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "nk87VBSQndA5"
      },
      "outputs": [],
      "source": [
        "model.load_weights(fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "m1ks758inc_Z"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Y_CHGgYja_bB"
      },
      "outputs": [],
      "source": [
        "pred=model.predict(df_X_minmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "loCl2-qmA6SL"
      },
      "outputs": [],
      "source": [
        "def maxpos(alist):\n",
        "    temp = max(alist)\n",
        "    res = [i for i, j in enumerate(alist) if j == temp]\n",
        "    return res[0]  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "CIFRZ753bMNi"
      },
      "outputs": [],
      "source": [
        "#from IPython.lib.display import YouTubeVideo\n",
        "def show_difference(pred,ytrain,verbose=False, only_wrong=True, to_table=False):\n",
        "    ecounter=0\n",
        "    o=[]\n",
        "    for i in range(len(pred)):\n",
        "        predi=pred[i]\n",
        "        traini=ytrain[i]\n",
        "        if abs(predi-traini)>0.5:\n",
        "            ecounter+=1\n",
        "            o.append(i)\n",
        "        if verbose:\n",
        "            if only_wrong:\n",
        "                \n",
        "                if abs(predi-traini)>0.5: \n",
        "                    if to_table:\n",
        "                        print(f\"|{i}|{predi}|{traini}|\")\n",
        "                    else:\n",
        "                        print(f\"{i}, {predi}, {traini}\")\n",
        "                \n",
        "            else:\n",
        "                print(f\"{i}, {predi}, {traini}\")\n",
        "\n",
        "                \n",
        "    print(f\"Hiba szám: {ecounter:6}, arány: {ecounter/len(ytrain)*100:3.2f}% \")\n",
        "    return(o)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "A7akwJMQ8Oza",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "14cd3727-f451-4bff-a743-c8ccdc4b53d5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 time        0  0.00333333  0.00666667      0.01  0.0133333  \\\n",
              "0  M13127N_detect3020  1.68793     1.41315    0.755643  0.480864   0.255152   \n",
              "1  M13144N_detect3020  1.92345     1.32483    0.863592  0.559372   0.323847   \n",
              "2  M13153N_detect3020  1.88420     1.27576    0.853778  0.569185   0.333661   \n",
              "3  M14028N_detect3020  0.00000     1.42296    0.942100  0.598626   0.382728   \n",
              "4  M14049N_detect3020  1.59961     1.07949    0.706575  0.441609   0.235525   \n",
              "\n",
              "   0.0166667      0.02  0.0233333  0.0266667  ...  47.92  47.9233  47.9267  \\\n",
              "0   0.107949  0.000000        0.0        0.0  ...    0.0      0.0      0.0   \n",
              "1   0.176644  0.039254        0.0        0.0  ...    0.0      0.0      0.0   \n",
              "2   0.166830  0.039254        0.0        0.0  ...    0.0      0.0      0.0   \n",
              "3   0.206084  0.058881        0.0        0.0  ...    0.0      0.0      0.0   \n",
              "4   0.117762  0.000000        0.0        0.0  ...    0.0      0.0      0.0   \n",
              "\n",
              "   47.93  47.9333  47.9367  47.94  Unnamed: 14384  Unnamed: 14385  coded  \n",
              "0    0.0      0.0      0.0    0.0     2524.709798        megfelel      0  \n",
              "1    0.0      0.0      0.0    0.0     2422.244040        megfelel      0  \n",
              "2    0.0      0.0      0.0    0.0     2529.530277        megfelel      0  \n",
              "3    0.0      0.0      0.0    0.0     2433.146990        megfelel      0  \n",
              "4    0.0      0.0      0.0    0.0     2652.605677        megfelel      0  \n",
              "\n",
              "[5 rows x 14387 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f4109ac-88f3-4428-9420-730f087817fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>0</th>\n",
              "      <th>0.00333333</th>\n",
              "      <th>0.00666667</th>\n",
              "      <th>0.01</th>\n",
              "      <th>0.0133333</th>\n",
              "      <th>0.0166667</th>\n",
              "      <th>0.02</th>\n",
              "      <th>0.0233333</th>\n",
              "      <th>0.0266667</th>\n",
              "      <th>...</th>\n",
              "      <th>47.92</th>\n",
              "      <th>47.9233</th>\n",
              "      <th>47.9267</th>\n",
              "      <th>47.93</th>\n",
              "      <th>47.9333</th>\n",
              "      <th>47.9367</th>\n",
              "      <th>47.94</th>\n",
              "      <th>Unnamed: 14384</th>\n",
              "      <th>Unnamed: 14385</th>\n",
              "      <th>coded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M13127N_detect3020</td>\n",
              "      <td>1.68793</td>\n",
              "      <td>1.41315</td>\n",
              "      <td>0.755643</td>\n",
              "      <td>0.480864</td>\n",
              "      <td>0.255152</td>\n",
              "      <td>0.107949</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2524.709798</td>\n",
              "      <td>megfelel</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M13144N_detect3020</td>\n",
              "      <td>1.92345</td>\n",
              "      <td>1.32483</td>\n",
              "      <td>0.863592</td>\n",
              "      <td>0.559372</td>\n",
              "      <td>0.323847</td>\n",
              "      <td>0.176644</td>\n",
              "      <td>0.039254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2422.244040</td>\n",
              "      <td>megfelel</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M13153N_detect3020</td>\n",
              "      <td>1.88420</td>\n",
              "      <td>1.27576</td>\n",
              "      <td>0.853778</td>\n",
              "      <td>0.569185</td>\n",
              "      <td>0.333661</td>\n",
              "      <td>0.166830</td>\n",
              "      <td>0.039254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2529.530277</td>\n",
              "      <td>megfelel</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M14028N_detect3020</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.42296</td>\n",
              "      <td>0.942100</td>\n",
              "      <td>0.598626</td>\n",
              "      <td>0.382728</td>\n",
              "      <td>0.206084</td>\n",
              "      <td>0.058881</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2433.146990</td>\n",
              "      <td>megfelel</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M14049N_detect3020</td>\n",
              "      <td>1.59961</td>\n",
              "      <td>1.07949</td>\n",
              "      <td>0.706575</td>\n",
              "      <td>0.441609</td>\n",
              "      <td>0.235525</td>\n",
              "      <td>0.117762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2652.605677</td>\n",
              "      <td>megfelel</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 14387 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f4109ac-88f3-4428-9420-730f087817fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f4109ac-88f3-4428-9420-730f087817fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f4109ac-88f3-4428-9420-730f087817fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[188]"
      ],
      "metadata": {
        "id": "1FCxVKUDhery",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41b8c7a-7e17-4bc1-9c5f-51dc40bbf186"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time              M09038N_detect3020\n",
              "0                            1.24632\n",
              "0.00333333                  0.726202\n",
              "0.00666667                  0.382728\n",
              "0.01                        0.107949\n",
              "                         ...        \n",
              "47.9367                          0.0\n",
              "47.94                            0.0\n",
              "Unnamed: 14384           2564.065315\n",
              "Unnamed: 14385         nem felel meg\n",
              "coded                              0\n",
              "Name: 188, Length: 14387, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "IWKt2DCcFbKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bc4131-7753-4cda-9f47-2e482382ea2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|31|[0.581002]|0|\n",
            "|33|[0.55741197]|0|\n",
            "|69|[0.69397795]|0|\n",
            "|83|[0.9394841]|0|\n",
            "|98|[0.7162458]|0|\n",
            "|105|[0.3015607]|1|\n",
            "|120|[0.8928878]|0|\n",
            "|122|[0.53754544]|0|\n",
            "|126|[0.6838147]|0|\n",
            "|128|[0.56713516]|0|\n",
            "|130|[0.9465398]|0|\n",
            "|131|[0.86233675]|0|\n",
            "|134|[0.98446786]|0|\n",
            "|142|[0.8000948]|0|\n",
            "|147|[0.7837119]|0|\n",
            "|150|[0.6307967]|0|\n",
            "|155|[0.5968729]|0|\n",
            "|158|[0.5983822]|0|\n",
            "|165|[0.6626994]|0|\n",
            "|166|[0.8198546]|0|\n",
            "|173|[0.6976248]|0|\n",
            "|186|[0.09029222]|1|\n",
            "Hiba szám:     22, arány: 10.73% \n"
          ]
        }
      ],
      "source": [
        "wrong_prediction_list=show_difference(pred,df_y2,verbose=True,to_table=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bwUpz9KG73GH"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batchID(df,index_list):\n",
        "    for i in index_list:\n",
        "        print(f\"{i:4}. --> {df.iloc[i].time.split('_')[0]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3UF3Gzmf7vFt"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OV04pFpA8_dj"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_batchID(df,wrong_prediction_list)"
      ],
      "metadata": {
        "id": "Wo65biL-8djO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0358091a-e95c-467b-f4f9-e0bd48d263fe"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  31. --> M5C011N\n",
            "  33. --> M68020N\n",
            "  69. --> M8A180N\n",
            "  83. --> M88042N\n",
            "  98. --> M89160N\n",
            " 105. --> M8A048N\n",
            " 120. --> M88091N\n",
            " 122. --> M91001N\n",
            " 126. --> M9B085N\n",
            " 128. --> M92107N\n",
            " 130. --> M91013N\n",
            " 131. --> M92126N\n",
            " 134. --> M91020N\n",
            " 142. --> M98006N\n",
            " 147. --> M99054N\n",
            " 150. --> M99132N\n",
            " 155. --> M91104N\n",
            " 158. --> M9A061N\n",
            " 165. --> M9B014N\n",
            " 166. --> M9B060N\n",
            " 173. --> M92062N2\n",
            " 186. --> M09004N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "x39xe3TmGHJ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "674e43c3-2e39-43cf-9746-e6cbf40a5080"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-29e0c3615294>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ---\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypng\n",
        "!pip install pyqrcode"
      ],
      "metadata": {
        "id": "MsQ2eUE8GZc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pyqrcode\n",
        "link_1 = pyqrcode.create('https://www.linkedin.com/in/36204746473/')\n",
        "link_1.png(\"p1.png\",scale=3,module_color=(20,20,20,255), background=(200,200,200,255))"
      ],
      "metadata": {
        "id": "WzKez2bME9eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlKyrRqfG6GP"
      },
      "source": [
        "### Model usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvmmKvBIF4n8"
      },
      "outputs": [],
      "source": [
        "test_df=pd.read_csv(\"test_200.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc0vyTmcHRvY"
      },
      "outputs": [],
      "source": [
        "print(len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5utaqxGNHU7y"
      },
      "outputs": [],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykk17oAEoPwM"
      },
      "outputs": [],
      "source": [
        "__MAXWORD__=200\n",
        "test_word_list=list(test_df.Words_in_Numbers)\n",
        "x_test=create_x(test_word_list,maxword=__MAXWORD__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg0DqmUWoj5s"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itw7lX_hqO5m"
      },
      "outputs": [],
      "source": [
        "o=[\"kitaifa\",\"michezo\",\"biashara\",\"kamataifa\",\"burudani\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOQFlEC2oj2i"
      },
      "outputs": [],
      "source": [
        "def data_generator(y_pred):\n",
        "    out=[]\n",
        "    for pred in y_pred:\n",
        "        t1=[0,0,0,0,0]\n",
        "        ox=pred.argmax()\n",
        "        t1[ox]=1\n",
        "        out.append(t1) \n",
        "    return(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSRQc0kWojzb"
      },
      "outputs": [],
      "source": [
        "output=data_generator(y_pred)\n",
        "\n",
        "output0=[x[0] for x in output]\n",
        "output1=[x[1] for x in output]\n",
        "output2=[x[2] for x in output]\n",
        "output3=[x[3] for x in output]\n",
        "output4=[x[4] for x in output]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G88pQ7jYojvu"
      },
      "outputs": [],
      "source": [
        "df_csv=pd.DataFrame()\n",
        "df_csv[\"test_id\"]=test_df[\"swahili_id\"]\n",
        "df_csv[o[0]]=output0\n",
        "df_csv[o[1]]=output1\n",
        "df_csv[o[2]]=output2\n",
        "df_csv[o[3]]=output3\n",
        "df_csv[o[4]]=output4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NSaY0zkyu1t"
      },
      "outputs": [],
      "source": [
        "df_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw4CUPobbH7A"
      },
      "outputs": [],
      "source": [
        "from datetime  import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAbhqmcPdF6U"
      },
      "outputs": [],
      "source": [
        "a=datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiOwO9UTdeUt"
      },
      "outputs": [],
      "source": [
        "fname=\"submission_\"+a+\".csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ELciPC_OpWA"
      },
      "outputs": [],
      "source": [
        "df_csv.to_csv(fname,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvmaQZGBYM_7"
      },
      "outputs": [],
      "source": [
        "!head $fname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrtPBTgcYwtg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "HPLC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}